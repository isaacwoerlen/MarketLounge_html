<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <title>README_faiss_pgvector_recommandations.md</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <h1>README_faiss_pgvector_recommandations.md</h1>
    <pre><code>ðŸ“‹ Recommandations pour le dÃ©veloppeur â€” App faiss_pgvector
Ce document fournit des recommandations pour dÃ©velopper et maintenir lâ€™app faiss_pgvector, une app transversale pour la vectorisation et la recherche sÃ©mantique, utilisÃ©e par toutes les apps verticales (ex: language, glossary, champs SEO/OG). Suivez ces pratiques pour garantir un code robuste, scalable, et prÃªt pour lâ€™IA sÃ©mantique, tout en respectant les conventions de README Brief Technique.md.
ðŸ›  Ordre de dÃ©veloppement recommandÃ©

Configurer les bases :
ImplÃ©menter apps.py (FaissPgvectorConfig pour signaux) et settings.py (EMBEDDING_DIM, FAISS_ENABLED, etc.).
Tester : tests/test_settings.py (valider EMBEDDING_DIM > 0, FAISS_ENABLED or PGVECTOR_ENABLED).


DÃ©finir la faÃ§ade :
CrÃ©er services.py avec API publique (encode_text, store_vector, search_similar, upsert, build) sous forme de stubs.
Tester : tests/test_services.py (valider signatures, exceptions).


Backend pgvector :
ImplÃ©menter specific/pgvector_backend.py (store_vector, fetch_vectors).
Tester : tests/test_pgvector_backend.py (stockage/lecture, dimension).


Backend FAISS :
ImplÃ©menter specific/faiss_backend.py (build_index, search_similar, upsert).
Tester : tests/test_faiss_backend.py (top-k, idempotence).


Connecter la faÃ§ade :
ComplÃ©ter services.py pour router vers pgvector_backend et faiss_backend.
Tester : tests/test_services.py (intÃ©gration complÃ¨te).


TÃ¢ches Celery :
ImplÃ©menter tasks.py (sync_embeddings, recalculate_embeddings, monitor_index).
Tester : tests/test_tasks.py (cohÃ©rence pgvector/FAISS, stats).


Commandes CLI :
ImplÃ©menter management/commands/sync_faiss_index.py (appelle sync_embeddings) et rebuild_collection.py (reconstruit index spÃ©cifique).
Tester : Valider via CLI.



ðŸ”‘ Bonnes pratiques

DÃ©couplage strict :
faiss_pgvector ne doit jamais importer language, glossary, ou LLM_ai.
Apps mÃ©tier appellent transversales.faiss_pgvector.services (ex: encode_text, search_similar).
Pourquoi : Ã‰vite les cycles, permet de remplacer FAISS par Milvus/Weaviate sans toucher les apps mÃ©tier.


Normalisation & mÃ©trique :
Normaliser tous les vecteurs (L2) dans encode_text pour cohÃ©rence cosine.
Utiliser vector_cosine_ops (pgvector) et IndexFlatIP (FAISS, vecteurs normalisÃ©s).
VÃ©rifier dans services.py : vector.shape == (settings.EMBEDDING_DIM,) et dtype float32.
Pourquoi : Garantit des scores cohÃ©rents entre pgvector et FAISS.


Idempotence :
store_vector : Mettre Ã  jour obj.embedding sans .save().
upsert : Supporter rÃ©-exÃ©cutions (ex: mise Ã  jour si ID existe).
build : Ã‰crire atomiquement (.index.tmp â†’ rename).
Pourquoi : Ã‰vite les erreurs en batch ou retry.


Multi-tenant et scope :
Utiliser collection = f"{tenant_id or 'default'}:{scope}" dans search_similar, upsert, build.
Stocker index FAISS dans faiss_index//.index.
Pourquoi : Ã‰vite collisions, supporte sharding.


Aucune persistance directe :
faiss_pgvector remplit obj.embedding mais ne fait jamais .save().
Apps mÃ©tier (language, glossary) gÃ¨rent la persistance.
Pourquoi : Respecte les frontiÃ¨res des apps mÃ©tier.


Utilisation du mixin :
Apps mÃ©tier doivent hÃ©riter de EmbeddingMixin (dans transversales.faiss_pgvector.models) pour dÃ©finir le champ embedding.


Configuration centralisÃ©e :
Utiliser settings.py pour EMBEDDING_DIM, EMBEDDING_MODEL, FAISS_ENABLED, PGVECTOR_ENABLED, FAISS_INDEX_DIR, LANG_EMBED_SYNC.
Valider via asserts (ex: assert EMBEDDING_DIM > 0).
Pourquoi : Ã‰vite incohÃ©rences (ex: dimension mismatch).


Tests prioritaires :
Tester chaque composant dÃ¨s son dÃ©veloppement :
encode_text : shape == (EMBEDDING_DIM,), dtype == float32, L2 â‰ˆ 1 (cosine).
store_vector : Stockage pgvector, lÃ¨ve erreur si dimension incorrecte.
search_similar : Top-1 renvoie ID correct, filtrage tenant_id/scope.
upsert : Idempotent (rÃ©-exÃ©cution sans crash).
build : Index cohÃ©rent avec pgvector.


Utiliser pytest, factory_boy, pytest-cov (voir tests/).



âš ï¸ PiÃ¨ges Ã  Ã©viter

Imports croisÃ©s :
Ne jamais importer language ou LLM_ai dans faiss_pgvector.
Solution : Utiliser services.py comme faÃ§ade publique.


IncohÃ©rence dimension :
Ne pas coder en dur 384 ; utiliser settings.EMBEDDING_DIM.
Solution : Valider dimensions dans encode_text, store_vector, upsert, build.


Persistance non atomique :
Ne pas Ã©crire directement .index ; utiliser .index.tmp â†’ rename.
Solution : ImplÃ©menter atomicitÃ© dans faiss_backend.build_index.


Manque de tests :
Ne pas dÃ©velopper sans tests unitaires pour chaque composant.
Solution : Suivre les tests rapides proposÃ©s (encode, store, search).


Couplage avec DB mÃ©tier :
Ne pas appeler .save() dans faiss_pgvector.
Solution : Laisser language/glossary gÃ©rer la DB.



ðŸš€ Exemple dâ€™intÃ©gration
Dans language :
from transversales.faiss_pgvector.services import encode_text, store_vector, search_similar
from transversales.faiss_pgvector.models import EmbeddingMixin

def vectorize_translation(translation):
    vector = encode_text(translation.text)
    store_vector(translation, vector)
    translation.save()  # Persistance par language
    similar = search_similar(vector, scope="translation", tenant_id=translation.key.tenant_id)
    if similar and similar[0][1] > 0.9:  # Seuil dans language
        # RÃ©utiliser traduction

Dans tasks.py (batch) :
from celery import shared_task
from django.conf import settings
from transversales.faiss_pgvector.services import upsert, build

@shared_task
def run_vectorize_scopes(scope, tenant_id):
    translations = Translation.objects.filter(key__scope=scope, key__tenant_id=tenant_id)
    vectors = [encode_text(t.text) for t in translations]
    ids = [str(t.id) for t in translations]
    collection = f"{tenant_id}:{scope}"
    upsert(collection, ids, vectors)
    build(collection, [(id, vec) for id, vec in zip(ids, vectors)])

ðŸ§ª Tests recommandÃ©s

Encodage :
def test_encode_text():
    vector = encode_text("test")
    assert vector.shape == (settings.EMBEDDING_DIM,)
    assert vector.dtype == np.float32
    assert abs(np.linalg.norm(vector) - 1.0) < 1e-6  # NormalisÃ© L2


Stockage :
@pytest.mark.django_db
def test_store_vector():
    translation = TranslationFactory()
    vector = encode_text(translation.text)
    store_vector(translation, vector)
    assert translation.embedding is not None
    assert len(translation.embedding) == settings.EMBEDDING_DIM


Recherche :
@pytest.mark.django_db
def test_search_similar():
    translation = TranslationFactory()
    vector = encode_text(translation.text)
    store_vector(translation, vector)
    results = search_similar(vector, scope="translation", tenant_id=translation.key.tenant_id)
    assert results[0][0] == str(translation.id)  # Top-1 correct



ðŸ“Œ Conclusion
Suivez cet ordre et ces pratiques pour dÃ©velopper faiss_pgvector de maniÃ¨re robuste, scalable, et dÃ©couplÃ©e. Priorisez les tests Ã  chaque Ã©tape et respectez les frontiÃ¨res entre apps transversales et verticales. Lâ€™app est prÃªte pour lâ€™IA sÃ©mantique (matching, enrichissement) et le multi-tenancy (sharding, scope).</code></pre>
</body>
</html>